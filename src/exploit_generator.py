#!/usr/bin/env python3
"""
Exploit Generator Module
Copyright (c) 2025 RHAZOUANE SALAH-EDDINE
All rights reserved.

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see <https://www.gnu.org/licenses/>.

PROPRIETARY NOTICE:
This software is the confidential and proprietary information of
RHAZOUANE SALAH-EDDINE. You shall not disclose such confidential
information and shall use it only in accordance with the terms
of the license agreement you entered into with RHAZOUANE SALAH-EDDINE.

Author: RHAZOUANE SALAH-EDDINE
Repository: https://github.com/THE-RZ1-x/Ai_Vuln_Scanner
Profile: https://github.com/THE-RZ1-x
Version: 2.0
"""

import os
import json
import logging
import asyncio
import argparse
import sys
import traceback
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime
import yaml
import re
import urllib.request
import urllib.error
import socket
import ssl
from urllib.parse import urljoin, quote_plus

# Define MCP server availability flag
MCP_SERVER_AVAILABLE = False

# Try importing requests for better HTTP handling
try:
    import requests
    MCP_SERVER_AVAILABLE = True
except ImportError:
    # Fall back to urllib if requests is not available
    # Still mark as available since we'll use urllib as fallback
    MCP_SERVER_AVAILABLE = True
    logger.info("Requests module not available, falling back to urllib for HTTP requests")

# Conditional imports to handle missing packages gracefully
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    from openai import AsyncOpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

logger = logging.getLogger(__name__)

@dataclass
class MCPServerResult:
    """Class to store results from MCP server searches."""
    title: str
    description: str
    source: str
    content: str
    confidence: float
    timestamp: str
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert result to dictionary."""
        return {
            'title': self.title,
            'description': self.description,
            'source': self.source,
            'content': self.content,
            'confidence': self.confidence,
            'timestamp': self.timestamp
        }

class MCPServerBrowser:
    """Class to interface with MCP (Malware and CVE Provider) servers for vulnerability data.
    
    This class provides functionality to search for vulnerability information across multiple
    security databases and vulnerability repositories. It supports both synchronous and asynchronous
    operations and can fall back to different HTTP clients based on availability.
    
    It also provides AI-powered search capabilities when traditional database searches don't yield
    sufficient results, using OpenAI and Google Gemini models when available.
    """
    
    def __init__(self, base_urls: List[str] = None, timeout: int = 10, verbose: bool = False):
        """Initialize the MCP server browser.
        
        Args:
            base_urls: List of MCP server URLs to query. If None, defaults to a list of common
                       vulnerability databases (MITRE CVE, NVD, Exploit-DB).
            timeout: Timeout for HTTP requests in seconds. Default is 10 seconds.
            verbose: Enable verbose logging for detailed operation information.
        """
        self.base_urls = base_urls or [
            "https://cve.mitre.org/data/",
            "https://nvd.nist.gov/vuln/",
            "https://exploit-db.com/"
        ]
        self.timeout = timeout
        self.verbose = verbose
        self.available = MCP_SERVER_AVAILABLE
        self.session = None
        self.user_agent = 'AI-Vuln-Scanner/1.0'
        
        # Initialize HTTP session if requests is available
        if self.available and 'requests' in sys.modules:
            self.session = sys.modules['requests'].Session()
            # Set up session with appropriate headers and timeout
            self.session.headers.update({
                'User-Agent': self.user_agent,
                'Accept': 'application/json, text/html, */*',
                'Connection': 'keep-alive'
            })
            if self.verbose:
                logger.debug("Using requests library for HTTP operations")
        else:
            if self.verbose:
                logger.debug("Using urllib for HTTP operations")
        
        if verbose:
            logger.debug(f"MCP Server Browser initialized with {len(self.base_urls)} servers")
            logger.debug(f"MCP Server availability: {self.available}")
    
    async def search_vulnerability(self, query: str, max_results: int = 5, use_ai: bool = False) -> List[MCPServerResult]:
        """Search for vulnerability information across MCP servers.
        
        This method queries multiple vulnerability databases for information about a specific
        vulnerability or security issue. It handles errors gracefully and aggregates results
        from multiple sources.
        
        Args:
            query: Search query string (e.g., CVE ID, vulnerability name, or keywords)
            max_results: Maximum number of results to return (default: 5)
            use_ai: Whether to use AI models to enhance search results if traditional search
                   yields insufficient results (default: False)
            
        Returns:
            List of MCPServerResult objects containing vulnerability information
        """
        if not self.available:
            logger.warning("MCP Server Browser is not available")
            return []
        
        if not query or not isinstance(query, str) or len(query.strip()) == 0:
            logger.error("Invalid query provided")
            return []
        
        results = []
        errors = 0
        max_errors = 2  # Maximum number of errors before stopping search
        
        # Sanitize query
        safe_query = quote_plus(query.strip())
        
        if self.verbose:
            logger.debug(f"Starting vulnerability search for: {query}")
        
        for base_url in self.base_urls:
            try:
                # Skip if we've reached max errors
                if errors >= max_errors:
                    logger.warning(f"Too many errors encountered ({errors}), stopping search")
                    break
                
                # Skip if we've reached max results
                if len(results) >= max_results:
                    if self.verbose:
                        logger.debug(f"Reached maximum results ({max_results}), stopping search")
                    break
                
                # Construct search URL based on the server
                search_url = self._construct_search_url(base_url, safe_query)
                
                if self.verbose:
                    logger.debug(f"Searching MCP server: {search_url}")
                
                # Perform the search with timeout protection
                try:
                    server_results = await asyncio.wait_for(
                        self._perform_search(search_url),
                        timeout=self.timeout
                    )
                    
                    # Add results
                    if server_results:
                        remaining_slots = max_results - len(results)
                        results.extend(server_results[:remaining_slots])
                        if self.verbose:
                            logger.debug(f"Found {len(server_results)} results from {base_url}")
                    
                except asyncio.TimeoutError:
                    errors += 1
                    logger.warning(f"Timeout while searching {base_url}")
                    continue
                
            except Exception as e:
                errors += 1
                logger.error(f"Error searching MCP server {base_url}: {str(e)}")
                if self.verbose:
                    logger.error(traceback.format_exc())
        
        # If we have insufficient results and AI search is enabled, try AI-powered search
        if use_ai and len(results) < max_results:
            if self.verbose:
                logger.debug(f"Found only {len(results)} results, attempting AI-powered search")
            
            ai_results = await self.search_vulnerability_with_ai(query, max_results - len(results))
            if ai_results:
                results.extend(ai_results)
                if self.verbose:
                    logger.debug(f"Added {len(ai_results)} results from AI search")
        
        if self.verbose:
            logger.debug(f"Search completed. Found {len(results)} results in total")
            
        return results[:max_results]
    
    def _construct_search_url(self, base_url: str, query: str) -> str:
        """Construct appropriate search URL based on the server.
        
        This method creates the correct search URL format for different vulnerability databases.
        Each database has its own URL structure and query parameter format.
        
        Args:
            base_url: The base URL of the vulnerability database
            query: The sanitized search query
            
        Returns:
            Properly formatted search URL for the specified database
        """
        if "cve.mitre.org" in base_url:
            return urljoin(base_url, f"search/cveresults.cfm?keyword={query}")
        elif "nvd.nist.gov" in base_url:
            return urljoin(base_url, f"search/results?form_type=Basic&results_type=overview&query={query}")
        elif "exploit-db.com" in base_url:
            return urljoin(base_url, f"search?q={query}")
        elif "cvedetails.com" in base_url:
            return urljoin(base_url, f"cve/search.php?search={query}")
        elif "vuldb.com" in base_url:
            return urljoin(base_url, f"search?search={query}")
        else:
            # Generic search URL format
            return urljoin(base_url, f"search?q={query}")
    
    async def _perform_search(self, url: str) -> List[MCPServerResult]:
        """Perform the actual search request and parse results.
        
        This method handles the HTTP request to the vulnerability database and processes
        the response. It supports both the requests library and urllib as fallback.
        
        Args:
            url: The complete search URL to query
            
        Returns:
            List of MCPServerResult objects containing parsed vulnerability information
        """
        results = []
        content = None
        status_code = None
        
        try:
            # Use requests if available, otherwise fall back to urllib
            if self.session:
                try:
                    # Use asyncio.to_thread to make the synchronous request non-blocking
                    response = await asyncio.to_thread(
                        self.session.get, 
                        url, 
                        timeout=self.timeout,
                        allow_redirects=True
                    )
                    content = response.text
                    status_code = response.status_code
                except Exception as req_error:
                    logger.warning(f"Error using requests: {str(req_error)}, falling back to urllib")
                    # Fall back to urllib if requests fails
                    self.session = None
            
            # Use urllib if requests is not available or failed
            if not self.session:
                try:
                    # Configure urllib with proper headers and SSL context
                    context = ssl.create_default_context()
                    headers = {'User-Agent': self.user_agent}
                    req = urllib.request.Request(url, headers=headers)
                    
                    with urllib.request.urlopen(req, timeout=self.timeout, context=context) as response:
                        content = response.read().decode('utf-8', errors='replace')
                        status_code = response.status
                except urllib.error.HTTPError as http_err:
                    status_code = http_err.code
                    logger.warning(f"HTTP Error: {http_err.code} - {http_err.reason} for {url}")
                    return results
                except urllib.error.URLError as url_err:
                    logger.warning(f"URL Error: {str(url_err)} for {url}")
                    return results
            
            # Check if request was successful
            if not content or status_code != 200:
                logger.warning(f"MCP server returned status code {status_code} for {url}")
                return results
            
            # Parse the response based on the URL
            if "cve.mitre.org" in url:
                results = self._parse_mitre_response(content, url)
            elif "nvd.nist.gov" in url:
                results = self._parse_nvd_response(content, url)
            elif "exploit-db.com" in url:
                results = self._parse_exploitdb_response(content, url)
            elif "cvedetails.com" in url:
                results = self._parse_cvedetails_response(content, url)
            else:
                # Generic parsing
                results = self._parse_generic_response(content, url)
            
            if self.verbose:
                logger.debug(f"Found {len(results)} results from {url}")
            
            return results
            
        except Exception as e:
            logger.error(f"Error performing search on {url}: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return []
    
    def _parse_mitre_response(self, content: str, url: str) -> List[MCPServerResult]:
        """Parse CVE MITRE search results.
        
        Extracts vulnerability information from MITRE CVE database search results.
        
        Args:
            content: HTML content from the search response
            url: The URL that was queried
            
        Returns:
            List of MCPServerResult objects with parsed CVE information
        """
        results = []
        
        try:
            # More robust regex pattern for MITRE CVE results
            # This pattern handles different HTML structures that might be present
            cve_pattern = r'<a href="/cgi-bin/cvename\.cgi\?name=(CVE-\d+-\d+)">(CVE-\d+-\d+)</a>.*?<td>(.*?)</td>'
            matches = re.finditer(cve_pattern, content, re.DOTALL)
            
            for match in matches:
                try:
                    cve_id = match.group(1)
                    description = match.group(3).strip()
                    
                    # Clean up the description - remove HTML tags and normalize whitespace
                    description = re.sub(r'<[^>]+>', '', description)
                    description = re.sub(r'\s+', ' ', description).strip()
                    
                    results.append(MCPServerResult(
                        title=cve_id,
                        description=description,
                        source="MITRE CVE",
                        content=f"CVE ID: {cve_id}\nDescription: {description}",
                        confidence=0.9,
                        timestamp=datetime.now().isoformat()
                    ))
                except Exception as e:
                    if self.verbose:
                        logger.debug(f"Error parsing MITRE CVE entry: {str(e)}")
                    continue
            
            # Alternative pattern for newer MITRE site format
            if not results:
                alt_pattern = r'<a href="/cve/([\w-]+)">(CVE-\d+-\d+)</a>.*?<td[^>]*>(.*?)</td>'
                alt_matches = re.finditer(alt_pattern, content, re.DOTALL)
                
                for match in alt_matches:
                    try:
                        cve_id = match.group(2)  # Use the displayed CVE ID
                        description = match.group(3).strip()
                        description = re.sub(r'<[^>]+>', '', description)
                        description = re.sub(r'\s+', ' ', description).strip()
                        
                        results.append(MCPServerResult(
                            title=cve_id,
                            description=description,
                            source="MITRE CVE",
                            content=f"CVE ID: {cve_id}\nDescription: {description}",
                            confidence=0.9,
                            timestamp=datetime.now().isoformat()
                        ))
                    except Exception as e:
                        if self.verbose:
                            logger.debug(f"Error parsing alternative MITRE CVE entry: {str(e)}")
                        continue
        except Exception as e:
            logger.error(f"Error parsing MITRE response: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
        
        return results
    
    def _parse_nvd_response(self, content: str, url: str) -> List[MCPServerResult]:
        """Parse NVD (National Vulnerability Database) search results.
        
        Extracts vulnerability information from NVD search results, including CVE IDs,
        CVSS scores, and vulnerability descriptions.
        
        Args:
            content: HTML content from the search response
            url: The URL that was queried
            
        Returns:
            List of MCPServerResult objects with parsed vulnerability information
        """
        results = []
        
        try:
            # Pattern for NVD vulnerability entries
            vuln_pattern = r'<a href="/vuln/detail/(CVE-\d+-\d+)">(CVE-\d+-\d+)</a>.*?<span class="[^"]*" data-testid="vuln-cvss3-link">(.*?)</span>'
            matches = re.finditer(vuln_pattern, content, re.DOTALL)
            
            for match in matches:
                try:
                    cve_id = match.group(1)
                    cvss_raw = match.group(3).strip()
                    
                    # Extract CVSS score
                    cvss_match = re.search(r'(\d+\.\d+)', cvss_raw)
                    cvss = cvss_match.group(1) if cvss_match else "N/A"
                    
                    # Try to find description - look for different possible patterns
                    description = "No description available"
                    desc_patterns = [
                        r'<p data-testid="vuln-description">(.*?)</p>',
                        r'<p class="vuln-detail-text">(.*?)</p>',
                        r'<p class="vuln-summary">(.*?)</p>'
                    ]
                    
                    for pattern in desc_patterns:
                        desc_match = re.search(pattern, content, re.DOTALL)
                        if desc_match:
                            description = desc_match.group(1).strip()
                            # Clean up description
                            description = re.sub(r'<[^>]+>', '', description)
                            description = re.sub(r'\s+', ' ', description).strip()
                            break
                    
                    # Try to find severity
                    severity = "Unknown"
                    severity_match = re.search(r'<span class="severity-rank"[^>]*>(.*?)</span>', content)
                    if severity_match:
                        severity = severity_match.group(1).strip()
                    
                    results.append(MCPServerResult(
                        title=cve_id,
                        description=description,
                        source="NVD",
                        content=f"CVE ID: {cve_id}\nCVSS: {cvss}\nSeverity: {severity}\nDescription: {description}",
                        confidence=0.85,
                        timestamp=datetime.now().isoformat()
                    ))
                except Exception as e:
                    if self.verbose:
                        logger.debug(f"Error parsing NVD entry: {str(e)}")
                    continue
            
            # If no results found with the first pattern, try an alternative pattern
            if not results:
                alt_pattern = r'<a[^>]*href="[^"]*detail/(CVE-\d+-\d+)"[^>]*>(CVE-\d+-\d+)</a>'
                alt_matches = re.finditer(alt_pattern, content, re.DOTALL)
                
                for match in alt_matches:
                    try:
                        cve_id = match.group(1)
                        
                        # Look for description near this CVE ID
                        context = content[max(0, match.start() - 200):min(len(content), match.end() + 500)]
                        desc_match = re.search(r'<p[^>]*>(.*?)</p>', context, re.DOTALL)
                        description = desc_match.group(1).strip() if desc_match else "No description available"
                        description = re.sub(r'<[^>]+>', '', description)
                        description = re.sub(r'\s+', ' ', description).strip()
                        
                        results.append(MCPServerResult(
                            title=cve_id,
                            description=description,
                            source="NVD",
                            content=f"CVE ID: {cve_id}\nDescription: {description}",
                            confidence=0.75,  # Lower confidence for alternative pattern
                            timestamp=datetime.now().isoformat()
                        ))
                    except Exception as e:
                        if self.verbose:
                            logger.debug(f"Error parsing alternative NVD entry: {str(e)}")
                        continue
        except Exception as e:
            logger.error(f"Error parsing NVD response: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
        
        return results
    
    def _parse_exploitdb_response(self, content: str, url: str) -> List[MCPServerResult]:
        """Parse Exploit-DB search results.
        
        Extracts exploit information from Exploit-DB search results, including exploit IDs,
        titles, dates, and platform information.
        
        Args:
            content: HTML content from the search response
            url: The URL that was queried
            
        Returns:
            List of MCPServerResult objects with parsed exploit information
        """
        results = []
        
        try:
            # Pattern for Exploit-DB entries - handle multiple possible formats
            exploit_patterns = [
                # Standard table format
                r'<a href="/exploits/(\d+)">(.*?)</a>.*?<td>(.*?)</td>',
                # Alternative card format
                r'<a href="/exploits/(\d+)"[^>]*>\s*<span[^>]*>(.*?)</span>.*?<div class="card-body">.*?Date:\s*([\d-]+)',
                # Simple link format
                r'<a href="/exploits/(\d+)"[^>]*>(.*?)</a>'
            ]
             
            for pattern in exploit_patterns:
                matches = re.finditer(pattern, content, re.DOTALL)
                
                for match in matches:
                    try:
                        exploit_id = match.group(1)
                        title = match.group(2).strip() if len(match.groups()) > 1 else f"Exploit {exploit_id}"
                        
                        # Extract date if available (group 3)
                        date = match.group(3).strip() if len(match.groups()) > 2 else "Unknown date"
                        
                        # Try to extract platform/type information
                        platform = "Unknown"
                        platform_match = re.search(r'<td[^>]*>([^<]+)</td>', content[match.start():match.start()+500])
                        if platform_match:
                            platform = platform_match.group(1).strip()
                        
                        # Clean up title - remove HTML tags
                        title = re.sub(r'<[^>]+>', '', title)
                        title = re.sub(r'\s+', ' ', title).strip()
                        
                        results.append(MCPServerResult(
                            title=title,
                            description=f"Exploit ID: {exploit_id}, Date: {date}, Platform: {platform}",
                            source="Exploit-DB",
                            content=f"Exploit ID: {exploit_id}\nTitle: {title}\nDate: {date}\nPlatform: {platform}",
                            confidence=0.8,
                            timestamp=datetime.now().isoformat()
                        ))
                    except Exception as e:
                        if self.verbose:
                            logger.debug(f"Error parsing Exploit-DB entry: {str(e)}")
                        continue
        except Exception as e:
            logger.error(f"Error parsing Exploit-DB response: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
        
        return results
    
    def _parse_cvedetails_response(self, content: str, url: str) -> List[MCPServerResult]:
        """Parse CVEDetails search results.
        
        Extracts vulnerability information from CVEDetails search results.
        
        Args:
            content: HTML content from the search response
            url: The URL that was queried
            
        Returns:
            List of MCPServerResult objects with parsed vulnerability information
        """
        results = []
        
        try:
            # Pattern for CVEDetails vulnerability entries
            cve_pattern = r'<a[^>]*href="/cve/([^"]+)"[^>]*>(CVE-\d+-\d+)</a>.*?<td[^>]*>(.*?)</td>'
            matches = re.finditer(cve_pattern, content, re.DOTALL)
            
            for match in matches:
                try:
                    cve_id = match.group(2)  # Use the displayed CVE ID
                    description = match.group(3).strip()
                    
                    # Clean up description
                    description = re.sub(r'<[^>]+>', '', description)
                    description = re.sub(r'\s+', ' ', description).strip()
                    
                    # Try to find CVSS score
                    cvss = "N/A"
                    cvss_match = re.search(r'<td[^>]*>([\d.]+)</td>', content[match.start():match.end()+200])
                    if cvss_match:
                        cvss = cvss_match.group(1).strip()
                    
                    results.append(MCPServerResult(
                        title=cve_id,
                        description=description,
                        source="CVEDetails",
                        content=f"CVE ID: {cve_id}\nCVSS: {cvss}\nDescription: {description}",
                        confidence=0.85,
                        timestamp=datetime.now().isoformat()
                    ))
                except Exception as e:
                    if self.verbose:
                        logger.debug(f"Error parsing CVEDetails entry: {str(e)}")
                    continue
        except Exception as e:
            logger.error(f"Error parsing CVEDetails response: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
        
        return results
    
    def _parse_generic_response(self, content: str, url: str) -> List[MCPServerResult]:
        """Generic parser for unknown MCP servers."""
        # This is a very basic implementation
        # In a real-world scenario, you would implement more sophisticated parsing
        results = []
        
        # Try to extract title
        title_match = re.search(r'<title>(.*?)</title>', content)
        title = title_match.group(1) if title_match else "Unknown Title"
        
        results.append(MCPServerResult(
            title=title,
            description=f"Content from {url}",
            source=url,
            content=content[:500] + "...",  # Truncate content for safety
            confidence=0.5,
            timestamp=datetime.now().isoformat()
        ))
        
        return results
        
    async def search_vulnerability_with_ai(self, query: str, max_results: int = 3) -> List[MCPServerResult]:
        """Search for vulnerability information using AI models.
        
        This method uses AI models (OpenAI and Google Gemini) to generate information about
        vulnerabilities when traditional database searches don't yield sufficient results.
        It formats the AI-generated information into MCPServerResult objects.
        
        Args:
            query: Search query string (e.g., CVE ID, vulnerability name, or keywords)
            max_results: Maximum number of results to return (default: 3)
            
        Returns:
            List of MCPServerResult objects containing AI-generated vulnerability information
        """
        results = []
        
        # Check if we have any AI models available
        openai_available = OPENAI_AVAILABLE and os.getenv("OPENAI_API_KEY")
        gemini_available = GEMINI_AVAILABLE and os.getenv("GEMINI_API_KEY")
        
        if not openai_available and not gemini_available:
            if self.verbose:
                logger.debug("No AI models available for vulnerability search")
            return results
            
        # Prepare the prompt for AI models
        prompt = self._create_vulnerability_search_prompt(query)
        
        # Try OpenAI first if available
        if openai_available:
            try:
                if self.verbose:
                    logger.debug("Attempting to search with OpenAI")
                    
                openai_results = await self._search_with_openai(prompt, max_results)
                if openai_results:
                    results.extend(openai_results)
                    if self.verbose:
                        logger.debug(f"Found {len(openai_results)} results with OpenAI")
            except Exception as e:
                logger.error(f"Error searching with OpenAI: {str(e)}")
                if self.verbose:
                    logger.error(traceback.format_exc())
        
        # If we still need more results and Gemini is available, try Gemini
        if len(results) < max_results and gemini_available:
            try:
                if self.verbose:
                    logger.debug("Attempting to search with Gemini")
                    
                gemini_results = await self._search_with_gemini(prompt, max_results - len(results))
                if gemini_results:
                    results.extend(gemini_results)
                    if self.verbose:
                        logger.debug(f"Found {len(gemini_results)} results with Gemini")
            except Exception as e:
                logger.error(f"Error searching with Gemini: {str(e)}")
                if self.verbose:
                    logger.error(traceback.format_exc())
        
        return results[:max_results]
        
    def _create_vulnerability_search_prompt(self, query: str) -> str:
        """Create a prompt for AI models to search for vulnerability information.
        
        Args:
            query: The vulnerability search query
            
        Returns:
            A formatted prompt for AI models
        """
        return f"""Please provide detailed information about the following security vulnerability or threat: {query}
        
        Format your response as a structured report with the following sections:
        1. Title: A concise name for the vulnerability
        2. Description: A detailed explanation of the vulnerability
        3. Technical Details: How the vulnerability works technically
        4. Impact: Potential consequences if exploited
        5. Affected Systems: Which systems, software, or versions are affected
        6. Mitigation: Steps to mitigate or patch the vulnerability
        7. References: Any CVE IDs, research papers, or other references
        
        Provide factual, accurate information only. If information is uncertain, indicate this clearly.
        """
    
    async def _search_with_openai(self, prompt: str, max_results: int) -> List[MCPServerResult]:
        """Search for vulnerability information using OpenAI.
        
        Args:
            prompt: The formatted prompt to send to OpenAI
            max_results: Maximum number of results to return
            
        Returns:
            List of MCPServerResult objects with AI-generated information
        """
        results = []
        
        try:
            # Initialize OpenAI client
            openai_key = os.getenv("OPENAI_API_KEY")
            if not openai_key:
                logger.error("OpenAI API key not found in environment variables")
                return results
                
            client = AsyncOpenAI(api_key=openai_key)
            
            # Try different models in order of preference
            models = ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"]
            response = None
            last_error = None
            
            for model in models:
                try:
                    if self.verbose:
                        logger.debug(f"Attempting to use OpenAI model: {model}")
                        
                    response = await client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": "You are a cybersecurity expert specializing in vulnerability research and analysis."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.3,  # Lower temperature for more factual responses
                        max_tokens=1000,
                        timeout=30  # Add timeout to prevent hanging
                    )
                    break
                except Exception as e:
                    last_error = e
                    if self.verbose:
                        logger.debug(f"Failed to use model {model}: {str(e)}")
                    continue
            
            if not response:
                if last_error:
                    logger.error(f"All OpenAI models failed: {str(last_error)}")
                return results
                
            # Process the response
            content = response.choices[0].message.content
            
            # Parse the response to extract structured information
            sections = self._parse_ai_vulnerability_response(content)
            
            # Create MCPServerResult objects
            if sections.get('title') and sections.get('description'):
                result = MCPServerResult(
                    title=sections.get('title', 'AI-Generated Vulnerability Information'),
                    description=sections.get('description', 'No description available'),
                    source="OpenAI",
                    content=content,
                    confidence=0.8,  # AI-generated content has slightly lower confidence
                    timestamp=datetime.now().isoformat()
                )
                results.append(result)
                
                # If we have technical details or impact information, add as separate results
                if sections.get('technical_details') and len(results) < max_results:
                    results.append(MCPServerResult(
                        title=f"Technical Details: {sections.get('title', 'Vulnerability')}",
                        description=sections.get('technical_details', ''),
                        source="OpenAI",
                        content=f"Technical Details:\n{sections.get('technical_details', '')}",
                        confidence=0.75,
                        timestamp=datetime.now().isoformat()
                    ))
                    
                if sections.get('mitigation') and len(results) < max_results:
                    results.append(MCPServerResult(
                        title=f"Mitigation: {sections.get('title', 'Vulnerability')}",
                        description=sections.get('mitigation', ''),
                        source="OpenAI",
                        content=f"Mitigation:\n{sections.get('mitigation', '')}",
                        confidence=0.75,
                        timestamp=datetime.now().isoformat()
                    ))
            
            return results[:max_results]
            
        except Exception as e:
            logger.error(f"Error in OpenAI vulnerability search: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return results
    
    async def _search_with_gemini(self, prompt: str, max_results: int) -> List[MCPServerResult]:
        """Search for vulnerability information using Google Gemini.
        
        Args:
            prompt: The formatted prompt to send to Gemini
            max_results: Maximum number of results to return
            
        Returns:
            List of MCPServerResult objects with AI-generated information
        """
        results = []
        
        try:
            # Initialize Gemini
            gemini_key = os.getenv("GEMINI_API_KEY")
            if not gemini_key:
                logger.error("Gemini API key not found in environment variables")
                return results
                
            genai.configure(api_key=gemini_key)
            
            # Try to use the latest model, with fallbacks
            model_names = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
            model = None
            
            for model_name in model_names:
                try:
                    model = genai.GenerativeModel(model_name)
                    if self.verbose:
                        logger.debug(f"Using Gemini model: {model_name}")
                    break
                except Exception as e:
                    if self.verbose:
                        logger.debug(f"Could not initialize {model_name}: {str(e)}")
                    continue
            
            if not model:
                logger.error("Failed to initialize any Gemini model")
                return results
                
            # Generate content with timeout protection
            response_text = None
            try:
                # Try to use async API if available
                if hasattr(model, 'generate_content_async'):
                    response = await asyncio.wait_for(
                        model.generate_content_async(prompt),
                        timeout=30
                    )
                else:
                    # Fall back to sync API
                    response = await asyncio.to_thread(model.generate_content, prompt)
                
                # Extract text from response based on response structure
                if hasattr(response, 'text'):
                    response_text = response.text
                elif hasattr(response, 'parts') and len(response.parts) > 0:
                    response_text = response.parts[0].text
                else:
                    # Try additional response formats
                    if hasattr(response, 'candidates') and len(response.candidates) > 0:
                        if hasattr(response.candidates[0], 'content') and hasattr(response.candidates[0].content, 'parts'):
                            response_text = response.candidates[0].content.parts[0].text
            except asyncio.TimeoutError:
                logger.error("Gemini API request timed out")
                return results
            except Exception as e:
                logger.error(f"Error generating content with Gemini: {str(e)}")
                if self.verbose:
                    logger.error(traceback.format_exc())
                return results
                
            if not response_text:
                logger.error("Failed to extract text from Gemini response")
                return results
                
            # Parse the response to extract structured information
            sections = self._parse_ai_vulnerability_response(response_text)
            
            # Create MCPServerResult objects
            if sections.get('title') and sections.get('description'):
                result = MCPServerResult(
                    title=sections.get('title', 'AI-Generated Vulnerability Information'),
                    description=sections.get('description', 'No description available'),
                    source="Google Gemini",
                    content=response_text,
                    confidence=0.8,  # AI-generated content has slightly lower confidence
                    timestamp=datetime.now().isoformat()
                )
                results.append(result)
                
                # If we have technical details or impact information, add as separate results
                if sections.get('technical_details') and len(results) < max_results:
                    results.append(MCPServerResult(
                        title=f"Technical Details: {sections.get('title', 'Vulnerability')}",
                        description=sections.get('technical_details', ''),
                        source="Google Gemini",
                        content=f"Technical Details:\n{sections.get('technical_details', '')}",
                        confidence=0.75,
                        timestamp=datetime.now().isoformat()
                    ))
                    
                if sections.get('mitigation') and len(results) < max_results:
                    results.append(MCPServerResult(
                        title=f"Mitigation: {sections.get('title', 'Vulnerability')}",
                        description=sections.get('mitigation', ''),
                        source="Google Gemini",
                        content=f"Mitigation:\n{sections.get('mitigation', '')}",
                        confidence=0.75,
                        timestamp=datetime.now().isoformat()
                    ))
            
            return results[:max_results]
            
        except Exception as e:
            logger.error(f"Error in Gemini vulnerability search: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return results
    
    def _parse_ai_vulnerability_response(self, response: str) -> Dict[str, str]:
        """Parse AI response to extract structured vulnerability information.
        
        Args:
            response: The raw text response from the AI model
            
        Returns:
            Dictionary containing parsed sections of the vulnerability information
        """
        sections = {
            'title': '',
            'description': '',
            'technical_details': '',
            'impact': '',
            'affected_systems': '',
            'mitigation': '',
            'references': ''
        }
        
        try:
            # Extract title - look for patterns like "Title:" or "#" headings
            title_patterns = [
                r'(?:^|\n)\s*Title:\s*(.+?)\s*(?:\n|$)',
                r'(?:^|\n)\s*#\s*(.+?)\s*(?:\n|$)',
                r'(?:^|\n)\s*\*\*(.+?)\*\*\s*(?:\n|$)'
            ]
            
            for pattern in title_patterns:
                title_match = re.search(pattern, response)
                if title_match:
                    sections['title'] = title_match.group(1).strip()
                    break
                    
            # If no title found, use the first line as title
            if not sections['title']:
                first_line = response.split('\n')[0].strip()
                if first_line and len(first_line) < 100:  # Reasonable title length
                    sections['title'] = first_line
                else:
                    sections['title'] = 'AI-Generated Vulnerability Information'
            
            # Extract description
            desc_patterns = [
                r'(?:^|\n)\s*Description:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)',
                r'(?:^|\n)\s*\d\.\s*Description:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)'
            ]
            
            for pattern in desc_patterns:
                desc_match = re.search(pattern, response, re.DOTALL)
                if desc_match:
                    sections['description'] = desc_match.group(1).strip()
                    break
            
            # Extract technical details
            tech_patterns = [
                r'(?:^|\n)\s*Technical Details:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)',
                r'(?:^|\n)\s*\d\.\s*Technical Details:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)'
            ]
            
            for pattern in tech_patterns:
                tech_match = re.search(pattern, response, re.DOTALL)
                if tech_match:
                    sections['technical_details'] = tech_match.group(1).strip()
                    break
            
            # Extract impact
            impact_patterns = [
                r'(?:^|\n)\s*Impact:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)',
                r'(?:^|\n)\s*\d\.\s*Impact:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)'
            ]
            
            for pattern in impact_patterns:
                impact_match = re.search(pattern, response, re.DOTALL)
                if impact_match:
                    sections['impact'] = impact_match.group(1).strip()
                    break
            
            # Extract affected systems
            affected_patterns = [
                r'(?:^|\n)\s*Affected Systems:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)',
                r'(?:^|\n)\s*\d\.\s*Affected Systems:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)'
            ]
            
            for pattern in affected_patterns:
                affected_match = re.search(pattern, response, re.DOTALL)
                if affected_match:
                    sections['affected_systems'] = affected_match.group(1).strip()
                    break
            
            # Extract mitigation
            mitigation_patterns = [
                r'(?:^|\n)\s*Mitigation:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)',
                r'(?:^|\n)\s*\d\.\s*Mitigation:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)'
            ]
            
            for pattern in mitigation_patterns:
                mitigation_match = re.search(pattern, response, re.DOTALL)
                if mitigation_match:
                    sections['mitigation'] = mitigation_match.group(1).strip()
                    break
            
            # Extract references
            ref_patterns = [
                r'(?:^|\n)\s*References:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)',
                r'(?:^|\n)\s*\d\.\s*References:\s*(.+?)\s*(?:\n\s*\w+:|\n\s*\d\.\s*\w+:|$)'
            ]
            
            for pattern in ref_patterns:
                ref_match = re.search(pattern, response, re.DOTALL)
                if ref_match:
                    sections['references'] = ref_match.group(1).strip()
                    break
            
            # If description is still empty, use a portion of the response
            if not sections['description'] and len(response) > 0:
                # Use the first 200 characters as description
                sections['description'] = response[:200].strip()
                if len(response) > 200:
                    sections['description'] += '...'
            
            return sections
            
        except Exception as e:
            logger.error(f"Error parsing AI vulnerability response: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return sections

@dataclass
class ExploitTemplate:
    vulnerability_type: str
    language: str
    description: str
    prerequisites: List[str]
    code: str
    usage: str
    mitigation: str
    references: List[str]
    
    def is_valid(self) -> bool:
        """Check if the exploit template has all required fields."""
        return all([
            self.vulnerability_type,
            self.language,
            self.description,
            self.code,
            self.usage,
            self.mitigation
        ])
        
    def to_dict(self) -> Dict[str, Any]:
        """Convert template to dictionary."""
        return {
            'vulnerability_type': self.vulnerability_type,
            'language': self.language,
            'description': self.description,
            'prerequisites': self.prerequisites,
            'code': self.code,
            'usage': self.usage,
            'mitigation': self.mitigation,
            'references': self.references
        }

class ExploitGenerator:
    def __init__(self, exploit_dir: str = "exploit_gen", verbose: bool = False):
        """Initialize the exploit generator with AI models and security controls.
        
        Args:
            exploit_dir: Directory to store generated exploits
            verbose: Enable verbose logging
        """
        self.openai_client = None
        self.gemini_model = None
        self.exploit_dir = exploit_dir
        self.verbose = verbose
        
        # Set up logging level based on verbosity
        if verbose:
            logging.basicConfig(level=logging.DEBUG)
            logger.setLevel(logging.DEBUG)
        
        self.initialize_ai_models()
        self._ensure_exploit_directory()
        
    def _ensure_exploit_directory(self):
        """Create exploit directory if it doesn't exist."""
        if not os.path.exists(self.exploit_dir):
            os.makedirs(self.exploit_dir)
            # Create a README with safety warning
            readme_path = os.path.join(self.exploit_dir, "README.md")
            with open(readme_path, "w") as f:
                f.write(self._get_safety_notice())
                
    def _get_safety_notice(self) -> str:
        """Return safety notice for exploit directory."""
        return """#  Security Notice - Proof of Concept Exploits

These proof-of-concept (PoC) exploits are generated for **educational and research purposes only**.

##  WARNING
- These exploits are meant for authorized security testing ONLY
- Using these exploits against systems without permission is ILLEGAL
- The author takes NO responsibility for misuse of these exploits
- Always obtain proper authorization before testing

##  Responsible Usage
1. Only use in controlled testing environments
2. Always obtain explicit permission before testing
3. Follow responsible disclosure practices
4. Report vulnerabilities to affected vendors
5. Never use against production systems without authorization

##  Legal Disclaimer
This code is provided for educational purposes only. Usage for attacking targets without prior mutual consent is illegal. It is the end user's responsibility to obey all applicable laws. The author assumes no liability and is not responsible for any misuse or damage caused by this code.
"""
        
    def initialize_ai_models(self):
        """Initialize AI models for exploit generation."""
        try:
            # Initialize OpenAI
            self._initialize_openai()
                
            # Initialize Google Gemini
            self._initialize_gemini()
                
            # Log available models
            if self.verbose:
                if self.openai_client:
                    logger.debug("OpenAI model available for exploit generation")
                if self.gemini_model:
                    logger.debug("Gemini model available for exploit generation")
                if not self.openai_client and not self.gemini_model:
                    logger.debug("No AI models available for exploit generation")
                
        except Exception as e:
            logger.error(f"Error initializing AI models: {str(e)}")
            self.openai_client = None
            self.gemini_model = None
            
    def _initialize_openai(self):
        """Initialize OpenAI model with error handling."""
        if not OPENAI_AVAILABLE:
            logger.warning("OpenAI module not installed. Install with: pip install openai")
            self.openai_client = None
            return
            
        openai_key = os.getenv("OPENAI_API_KEY")
        if not openai_key:
            logger.warning("OpenAI API key not found. Set OPENAI_API_KEY environment variable.")
            self.openai_client = None
            return
            
        try:
            self.openai_client = AsyncOpenAI(api_key=openai_key)
            logger.info("OpenAI model initialized successfully")
        except Exception as e:
            logger.warning(f"Error initializing OpenAI model: {str(e)}")
            self.openai_client = None
            
    def _initialize_gemini(self):
        """Initialize Google Gemini model with error handling."""
        if not GEMINI_AVAILABLE:
            logger.warning("Google Generativeai module not installed. Install with: pip install google-generativeai")
            self.gemini_model = None
            return
            
        gemini_key = os.getenv("GEMINI_API_KEY")
        if not gemini_key:
            logger.warning("Gemini API key not found. Set GEMINI_API_KEY environment variable.")
            self.gemini_model = None
            return
            
        try:
            genai.configure(api_key=gemini_key)
            # Try to use the latest model, with fallbacks
            model_names = ['gemini-1.5-flash', 'gemini-1.5-pro', 'gemini-pro']
            
            for model_name in model_names:
                try:
                    self.gemini_model = genai.GenerativeModel(model_name)
                    logger.info(f"Gemini model initialized with {model_name}")
                    break
                except Exception as e:
                    if self.verbose:
                        logger.debug(f"Could not initialize {model_name}: {str(e)}")
                    continue
                    
            if not self.gemini_model:
                logger.warning("Failed to initialize any Gemini model")
        except Exception as e:
            logger.warning(f"Error initializing Gemini model: {str(e)}")
            self.gemini_model = None
            
    def validate_vulnerability(self, vulnerability: Dict) -> bool:
        """
        Validate vulnerability data to ensure it has required fields.
        
        Args:
            vulnerability: Dictionary containing vulnerability details
            
        Returns:
            True if vulnerability data is valid, False otherwise
        """
        required_fields = ['type', 'description']
        
        # Check for required fields
        for field in required_fields:
            if field not in vulnerability or not vulnerability[field]:
                logger.error(f"Missing required vulnerability field: {field}")
                return False
                
        # Validate data types
        if not isinstance(vulnerability.get('type'), str):
            logger.error("Vulnerability type must be a string")
            return False
            
        if not isinstance(vulnerability.get('description'), str):
            logger.error("Vulnerability description must be a string")
            return False
            
        return True
    
    async def generate_exploit(self, vulnerability: Dict) -> Optional[str]:
        """
        Generate a proof-of-concept exploit for a detected vulnerability.
        
        Args:
            vulnerability: Dictionary containing vulnerability details
            
        Returns:
            Path to the generated exploit file or None if generation failed
        """
        try:
            # Validate vulnerability data
            if not self.validate_vulnerability(vulnerability):
                logger.error("Invalid vulnerability data provided")
                return None
                
            # Check if any AI models are available
            if not self.openai_client and not self.gemini_model:
                logger.warning("No AI models available for exploit generation")
                return None
                
            # Generate exploit using available AI model
            exploit = None
            
            # Try OpenAI first if available
            if self.openai_client:
                logger.info("Generating exploit with OpenAI...")
                exploit = await self._generate_with_openai(vulnerability)
                
            # Fall back to Gemini if OpenAI fails or is not available
            if not exploit and self.gemini_model:
                logger.info("Generating exploit with Gemini...")
                exploit = await self._generate_with_gemini(vulnerability)
                
            if not exploit:
                logger.warning("Failed to generate exploit with any available AI model")
                return None
                
            # Validate generated exploit
            if not exploit.is_valid():
                logger.warning("Generated exploit is missing required fields")
                return None
                
            # Save exploit
            return await self._save_exploit(vulnerability, exploit)
            
        except Exception as e:
            logger.error(f"Error generating exploit: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return None
            
    async def _generate_with_openai(self, vulnerability: Dict) -> Optional[ExploitTemplate]:
        """Generate exploit using OpenAI."""
        try:
            # Prepare prompt with security controls
            prompt = self._create_secure_prompt(vulnerability)
            
            # Added error handling for API key validation
            if not self.openai_client:
                logger.error("OpenAI client not initialized properly")
                return None
                
            # Try different models in order of preference
            models = ["gpt-4", "gpt-4-turbo", "gpt-3.5-turbo"]
            response = None
            last_error = None
            
            for model in models:
                try:
                    if self.verbose:
                        logger.debug(f"Attempting to use OpenAI model: {model}")
                        
                    response = await self.openai_client.chat.completions.create(
                        model=model,
                        messages=[
                            {"role": "system", "content": "You are a secure exploit development assistant. Generate only proof-of-concept exploits with proper safety controls and documentation."},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.7,
                        timeout=30  # Add timeout to prevent hanging
                    )
                    break
                except Exception as e:
                    last_error = e
                    if self.verbose:
                        logger.debug(f"Failed to use model {model}: {str(e)}")
                    continue
            
            if not response:
                if last_error:
                    logger.error(f"All OpenAI models failed: {str(last_error)}")
                return None
                
            # Parse response into ExploitTemplate
            result = self._parse_ai_response(response.choices[0].message.content)
            
            if result and self.verbose:
                logger.debug(f"Successfully generated exploit with OpenAI model: {model}")
                
            return result
            
        except Exception as e:
            logger.error(f"OpenAI exploit generation error: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return None
            
    async def _generate_with_gemini(self, vulnerability: Dict) -> Optional[ExploitTemplate]:
        """Generate exploit using Google Gemini."""
        try:
            # Prepare prompt with security controls
            prompt = self._create_secure_prompt(vulnerability)
            
            # Check if model is initialized correctly
            if not self.gemini_model:
                logger.error("Gemini model not initialized properly")
                return None
            
            response = None
            response_text = None
                
            try:
                # Try to use async api if available with timeout handling
                try:
                    if self.verbose:
                        logger.debug("Attempting to use Gemini async API")
                    # Create a timeout for the async call
                    response = await asyncio.wait_for(
                        self.gemini_model.generate_content_async(prompt),
                        timeout=30
                    )
                except (AttributeError, TypeError, asyncio.TimeoutError) as e:
                    if self.verbose:
                        logger.debug(f"Falling back to sync API: {str(e)}")
                    # Fall back to sync api if async not available or times out
                    response = self.gemini_model.generate_content(prompt)
                
                # Extract text from response based on response structure
                if hasattr(response, 'text'):
                    response_text = response.text
                elif hasattr(response, 'parts') and len(response.parts) > 0:
                    response_text = response.parts[0].text
                else:
                    # Try additional response formats
                    if hasattr(response, 'candidates') and len(response.candidates) > 0:
                        if hasattr(response.candidates[0], 'content') and hasattr(response.candidates[0].content, 'parts'):
                            response_text = response.candidates[0].content.parts[0].text
                
                if not response_text:
                    logger.error("Gemini API returned unexpected response format")
                    if self.verbose and response:
                        logger.debug(f"Response type: {type(response)}, Response: {str(response)}")
                    return None
                
                # Parse response into ExploitTemplate
                result = self._parse_ai_response(response_text)
                
                if result and self.verbose:
                    logger.debug("Successfully generated exploit with Gemini model")
                    
                return result
                
            except Exception as e:
                logger.error(f"Error processing Gemini response: {str(e)}")
                if self.verbose:
                    logger.error(traceback.format_exc())
                return None
            
        except Exception as e:
            logger.error(f"Gemini exploit generation error: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return None
            
    def _create_secure_prompt(self, vulnerability: Dict) -> str:
        """Create a secure prompt for exploit generation."""
        return f"""Generate a proof-of-concept exploit template for educational purposes only.
        
Vulnerability Details:
Type: {vulnerability.get('type')}
Description: {vulnerability.get('description')}
Target: {vulnerability.get('target', 'Unknown')}

Requirements:
1. Include clear safety warnings
2. Add usage documentation
3. Include mitigation steps
4. Add references
5. Implement basic safety controls
6. Focus on demonstration, not weaponization

Generate the exploit in this format:
```yaml
vulnerability_type: str
language: str
description: str
prerequisites:
  - prerequisite1
  - prerequisite2
code: |
  # Your PoC code here
usage: str
mitigation: str
references:
  - reference1
  - reference2
```
"""
        
    def _parse_ai_response(self, response: str) -> Optional[ExploitTemplate]:
        """Parse AI response into ExploitTemplate with improved error handling."""
        if not response or not isinstance(response, str):
            logger.error("Invalid response received from AI model")
            return None
            
        try:
            # Extract YAML block with multiple pattern matching for robustness
            yaml_match = None
            patterns = [
                r"```yaml\n(.*?)```",  # Standard markdown YAML block
                r"```yml\n(.*?)```",   # Alternative YAML extension
                r"```\n(.*?)```"      # Generic code block as fallback
            ]
            
            for pattern in patterns:
                yaml_match = re.search(pattern, response, re.DOTALL)
                if yaml_match:
                    break
                    
            if not yaml_match:
                logger.error("No YAML block found in AI response")
                if self.verbose:
                    logger.debug(f"Response content: {response[:200]}...")
                return None
                
            yaml_content = yaml_match.group(1).strip()
            
            # Handle potential YAML parsing errors
            try:
                data = yaml.safe_load(yaml_content)
            except yaml.YAMLError as e:
                logger.error(f"YAML parsing error: {str(e)}")
                if self.verbose:
                    logger.debug(f"Problematic YAML content: {yaml_content[:200]}...")
                return None
                
            if not data or not isinstance(data, dict):
                logger.error("Invalid YAML structure in AI response")
                return None
                
            # Create exploit template with default values for missing fields
            prerequisites = data.get('prerequisites', [])
            if isinstance(prerequisites, str):
                # Handle case where prerequisites is a string instead of a list
                prerequisites = [prerequisites]
                
            references = data.get('references', [])
            if isinstance(references, str):
                # Handle case where references is a string instead of a list
                references = [references]
                
            return ExploitTemplate(
                vulnerability_type=data.get('vulnerability_type', ''),
                language=data.get('language', ''),
                description=data.get('description', ''),
                prerequisites=prerequisites if isinstance(prerequisites, list) else [],
                code=data.get('code', ''),
                usage=data.get('usage', ''),
                mitigation=data.get('mitigation', ''),
                references=references if isinstance(references, list) else []
            )
            
        except Exception as e:
            logger.error(f"Error parsing AI response: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return None
            
    async def _save_exploit(self, vulnerability: Dict, exploit: ExploitTemplate) -> Optional[str]:
        """Save generated exploit to file with improved error handling and path sanitization."""
        try:
            # Ensure exploit directory exists
            if not os.path.exists(self.exploit_dir):
                os.makedirs(self.exploit_dir, exist_ok=True)
                
            # Create timestamp and sanitized filename with additional security checks
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Sanitize vulnerability type for filename
            vuln_type = vulnerability.get('type', 'unknown')
            if not isinstance(vuln_type, str):
                vuln_type = 'unknown'
            
            # More thorough sanitization to prevent path traversal or invalid chars
            vuln_type = re.sub(r'[^a-zA-Z0-9]', '_', vuln_type)
            vuln_type = vuln_type[:50]  # Limit length to prevent excessively long filenames
            
            filename = f"{timestamp}_{vuln_type}_exploit"
            
            # Determine file extension based on language
            ext = self._get_file_extension(exploit.language)
            
            # Construct absolute path and verify it's within the exploit directory
            filepath = os.path.abspath(os.path.join(self.exploit_dir, f"{filename}{ext}"))
            exploit_dir_abs = os.path.abspath(self.exploit_dir)
            
            # Security check to prevent path traversal
            if not filepath.startswith(exploit_dir_abs):
                logger.error(f"Security error: File path {filepath} is outside the exploit directory")
                return None
            
            # Create exploit file with documentation
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(self._format_exploit_file(exploit))
                
            logger.info(f"Exploit saved to {filepath}")
            return filepath
            
        except Exception as e:
            logger.error(f"Error saving exploit: {str(e)}")
            if self.verbose:
                logger.error(traceback.format_exc())
            return None
            
    def _get_file_extension(self, language: str) -> str:
        """Get appropriate file extension for language."""
        extensions = {
            'python': '.py',
            'ruby': '.rb',
            'perl': '.pl',
            'php': '.php',
            'javascript': '.js',
            'typescript': '.ts',
            'shell': '.sh',
            'bash': '.sh',
            'powershell': '.ps1',
            'c': '.c',
            'cpp': '.cpp',
            'csharp': '.cs',
            'java': '.java',
            'go': '.go',
            'rust': '.rs'
        }
        return extensions.get(language.lower(), '.txt')
        
    def _format_exploit_file(self, exploit: ExploitTemplate) -> str:
        """Format exploit template into a well-documented file."""
        return f'''#!/usr/bin/env {exploit.language}
"""
 SECURITY WARNING - PROOF OF CONCEPT EXPLOIT
This code is for educational and research purposes only.
Usage against systems without explicit permission is ILLEGAL.

Vulnerability: {exploit.vulnerability_type}
Description: {exploit.description}

Prerequisites:
{chr(10).join(f"- {prereq}" for prereq in exploit.prerequisites)}

Usage:
{exploit.usage}

Mitigation:
{exploit.mitigation}

References:
{chr(10).join(f"- {ref}" for ref in exploit.references)}

Author: AI Vulnerability Scanner - Exploit Generator
Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
"""

{exploit.code}
'''

    async def test_exploit_generation(self, vulnerability_type: str, description: str) -> Optional[str]:
        """
        Test exploit generation with a sample vulnerability.
        
        Args:
            vulnerability_type: Type of vulnerability to generate exploit for
            description: Description of the vulnerability
            
        Returns:
            Path to the generated exploit file or None if generation failed
        """
        test_vulnerability = {
            'type': vulnerability_type,
            'description': description,
            'target': 'Test Target'
        }
        
        logger.info(f"Testing exploit generation for {vulnerability_type}")
        return await self.generate_exploit(test_vulnerability)


async def main():
    """
    Main function for command-line interface.
    """
    parser = argparse.ArgumentParser(description='AI-powered Exploit Generator')
    parser.add_argument('--type', '-t', help='Vulnerability type', required=False)
    parser.add_argument('--description', '-d', help='Vulnerability description', required=False)
    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose logging')
    parser.add_argument('--output-dir', '-o', help='Output directory for exploits', default='exploit_gen')
    parser.add_argument('--test', action='store_true', help='Run with test vulnerability')
    
    args = parser.parse_args()
    
    # Configure logging
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=log_level, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    
    # Initialize exploit generator
    generator = ExploitGenerator(exploit_dir=args.output_dir, verbose=args.verbose)
    
    # Check if any AI models are available
    if not generator.openai_client and not generator.gemini_model:
        logger.error("No AI models available. Please set up API keys.")
        logger.info("Set OPENAI_API_KEY or GEMINI_API_KEY environment variables.")
        return 1
    
    # Run test if requested
    if args.test:
        vuln_type = "SQL Injection"
        description = "A SQL injection vulnerability in the login form allows attackers to bypass authentication."
        logger.info(f"Running test with vulnerability type: {vuln_type}")
        
        exploit_path = await generator.test_exploit_generation(vuln_type, description)
        
        if exploit_path:
            logger.info(f"Test successful! Exploit generated at: {exploit_path}")
            return 0
        else:
            logger.error("Test failed. Could not generate exploit.")
            return 1
    
    # Generate exploit with provided details
    if args.type and args.description:
        vulnerability = {
            'type': args.type,
            'description': args.description,
            'target': 'Command Line Target'
        }
        
        exploit_path = await generator.generate_exploit(vulnerability)
        
        if exploit_path:
            logger.info(f"Exploit generated successfully at: {exploit_path}")
            return 0
        else:
            logger.error("Failed to generate exploit.")
            return 1
    else:
        if not args.test:
            parser.print_help()
        return 1


if __name__ == "__main__":
    asyncio.run(main())